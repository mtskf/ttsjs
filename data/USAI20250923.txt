アメリカAI最前線 20250923: VCの現場、AI動画、最新テック

先月は私が追いかけているテクノロジーのトレンドについて書きましたが、今月は「いまVCとして働くこと」について触れてみたいと思います。ちょうどファンド2をクローズしたところで、プレスリリースの代わりに遊び心で AI動画 を作ったので、その制作過程も紹介します。最後に、最近気になったおもしろい技術も少し共有します。
VCとしての経験
ベンチャーキャピタル（VC）はユニークな業界です。投資家からお金を集め、それをスタートアップに投資します。スタートアップが成長すれば投資家に利益が入り、十分にうまくいけばVC自身も利益を得ます。
株式、不動産、プライベートエクイティなど投資にはさまざまな分野がありますが、その中でもVCは最もリスクが高い分野です。例えば、投資資金を5倍に増やすような成功ファンドでも、 投資先の40％以上は失敗します 。よくあるのは、20社に投資したうちの1社が他のすべてを上回るリターンを生むケースです。
スタートアップが立ち上がってから「エグジット（上場やM&A）」までには通常7～10年かかります。VCファンドもそれを前提に設計されていて、最初の3年ほどで投資を行い、その後は長期的に支援し、10年ほどで投資家に資金と利益を返すのが一般的です。必要に応じて1～2年延長されることもあります。つまりVCは数年ごとに新しいファンドを立ち上げ、次の資金を集めながら、過去のファンドの支援も続けていくことになります。
ファンドの大きさは投資ステージによって変わります。私のように初期段階に投資する場合、企業の評価額も低く、調達額も小さいため、ファンドも500万～1,000万ドルほどの規模から始まります。一方で後期の投資では、1回で1億～10億ドルを投資することもあり、ファンド全体の規模は数百億～数千億円になります。小さなファンドは「お金に余裕のある人」やファミリーオフィス*から資金を集めます。大きなファンドになると、ファンド・オブ・ファンズや企業、年金基金、大学基金など、より大規模な機関投資家から資金を集めます。
ファミリーオフィスとは、大きな資産を持つ家族が自分たちの財産をまとめて管理・運用するための組織です。株式や不動産投資に加え、スタートアップ投資、寄付、相続対策などを扱い、いわば「家族専用の投資会社」のようなものです。欧米では一般的で、日本でも少しずつ増えてきています。小規模VCにとっては、スタートアップ投資に積極的なファミリーオフィスが重要な資金提供者になることもあります。
ここまで資金の話をしましたが、いちばん楽しいのはやはり実際の投資です。良いスタートアップを探し、投資するか決め、ときには競争に勝って資金を入れる。そして顧客を紹介したり、経営の相談に乗ったり、追加の資金調達を手伝ったりと支援を続けます。
VCにもそれぞれスタイルや重視するポイントがあります。データ分析に基づいて投資先を探す人もいれば、人間関係を中心に案件を見つける人もいます。財務データを細かく見る投資家もいれば、チームや創業者を重視する投資家もいます。一般的に、初期投資ではチームや創業者への評価が大きく、後期投資では売上成長や財務指標に重点が置かれます。私自身は初期投資をしていて、直感に頼る部分が多いタイプです。多くの企業を見て、市場について情報を集め、創業者の考え方を理解しようとしますが、最終的には「この人と一緒にやりたいか」という感覚で決めることが多いです。
投資そのものは簡単にできますが、本当に成果を出す投資は難しいです。その理由のひとつは「フィードバックループが長い」ことです。普通の仕事なら、うまくいかなかったことをすぐに学び、改善できます。しかしVCでは結果が出るまでに10年かかることもあり、自分の判断が正しかったかを確認できるのにとても時間がかかります。だからこそ投資家として成長するのが難しいのです。
VCは常に忙しいです。資金集め、新しいスタートアップとの出会い、投資判断、支援活動、ネットワークづくり。さらに運営や法務の管理も欠かせません。大変ではありますが、アイデアが実際のビジネスになり、顧客に価値を届け、雇用を生み出す姿を見るのはとてもやりがいがあります。
AI動画で遊んでみた
私はアーリーステージのベンチャーキャピタル「Untapped Capital」を運営していて、最近2つ目のファンドを立ち上げました。チームから「プレスリリースを出しますか？」と聞かれたとき、ふと思いついてAI動画を作ってみることにしました。最初に思いついたのは「ユニコーンと宇宙人が私たちについて話している」映像です。試しに短いクリップを作ってみたら思いのほか良かったので、そのまま進めることにしました。
完成した40秒ほどの動画 は、自分でもよくできたと思います。数時間で作れるのも驚きです。費用は約120ドルかかりましたが、数年前なら10倍以上のコストがかかっていたはずです。
最初に、車の後部座席に座るユニコーンと宇宙人の画像をAIで生成し、それをテキストから動画に変換するツールに入れました。最近はこの分野のツールが進化していますが、音声付きの動画を簡単に作れるツールはまだ少ないです。特に、複数キャラクターの画像をアップロードしてセリフを与えると、そのキャラクター同士が会話する動画を作ってくれるようなツールは存在しません。
「 Hedra 」は声の一貫性を保てますが、1つの動画につき1人しか話せません。「 MultiTalk 」は会話向けですが画質が低く使えませんでした。 Gemini で試した「Veo3」は音声付き動画のクオリティが高いのですが、2人が交互に話す指示は守ってくれません。最終的には「 Runway 」を使うことにしました。細かい会話は難しいですが、キャラクターが1回ずつ話す動画なら十分でした（裏でVeo3を使っていると後で気づいた）。
Runwayを使うことに決めてからは、最初の画像を元にChatGPTを使って、2人をさまざまな場面（カフェ、公園など）にいるイラストを生成しました。それをRunwayに入れて動画を作りました。シーンごとに1～3回試せば満足できるものができましたが、ときにはキャラクターが入れ替わったり、ノイズのような映像になることもありました。動画生成が一番コストがかかる部分で、Runwayだけで120ドルほど使いました。
揃えた動画は Canva でつなぎ合わせました。友人や同僚に見せると「テンポが少し遅い」と言われたので、セリフの間をカット。ただそのままだと映像が飛んで見えるので、キャラクターをズームイン・アウトさせて自然にしました。さらに全体を1.1倍速にして話し方を自然にし、最後に自動字幕ツールでキャプションを入れました。
AI動画ツールはそれぞれ特徴があり、まだ試したことがない人はぜひ一度使ってみてほしいです。今の技術の進化を実感できて楽しいと思います。
最近の面白い技術
最近のAI分野では、新しい画像モデル「 Reve 」が話題になっています。これは複数の写真を組み合わせて自然な画像を作れるツールです。たとえば「シーンの画像」「キャラクター」「服」を入力するとAIが自然に合成してくれます。既存の画像の中で物を動かすと周囲を修正して自然に見せたり、特定の部分だけを更新することもできます。従来の画像AIよりもコントロールの幅が広がっているのが特徴です。直近では「Nano Banana」というモデルも公開され、 Gemini で利用できます。さらに、動画生成の分野では「Wan 2.2」が注目を集めており、そのユニークなポイントはポーズコントロール機能で、唇の同期、ポーズの制御、ダンスなどのボディムーブメントを簡単に実現できる点です。キャラクターのオブジェクト画像と参照動画を提供するだけで、AIが自然な表情や動きを再現し、例えば歌唱時のリップシンクや複雑なダンスシーケンスを高品質に生成できます。Wan 2.2を試したい場合は、 wan.video にアクセスし、指示に従ってデモを利用できます。映画のような短編やソーシャルメディア向けのコンテンツ制作に最適です。
先月のスタートアップで特に未来的だと思ったのは「 AlterEgo 」です。声を出さなくてもコミュニケーションできる技術で、脳と声帯の筋肉の電気信号を読み取り、口を動かすだけで意図を理解します。テレパシーではありませんが、AIアシスタントや他の人に「声を出さずに」言葉を伝えることが可能です。日本では電車の中で音声入力をしたい人に役立ちそうです。
ユーザー体験の実験的な試みとしては「 Poke 」も印象的でした。数週間前にXで話題になったモバイルAIアプリで、iMessageを通じて会話できるAIの友達／アシスタントのような存在です。メールにもアクセスでき、最近届いたメールについて質問したり、重要なメールが来たときに通知してくれます。さらに、利用料をAIと交渉する仕組みがあり、Xでは「自分はいくらで契約できた」という投稿も見られます。ちょっと不思議ですが、AIを日常に自然に取り入れるための良い実験だと思います。
もうひとつ驚いたのは「 Lura Health 」です。これは歯に埋め込むセンサー型デバイスで、唾液のpHや代謝物を測定して健康状態をモニタリングします。スマホアプリでリアルタイムに確認でき、医師とデータを共有することも可能です。最初は埋め込み不要なマウスピースやリテーナーから始め、将来的には矯正器具やインプラントに組み込まれていくそうです。
