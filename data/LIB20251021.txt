週刊Life is beautiful ２０２５年１０月２１日号：ハロウィーンと秋景色、AIネイティブな時代のUI/UX、AIが置き換えるべき市場、OpenAIとBroadcomの契約、「AIブーム」と「AIバブル」

今週のざっくばらん

ハロウィーンと秋景色

ハロウィーンの季節が近づいて来ました。日本では、渋谷の歩行者天国で仮装をした若者が暴れるイメージがありますが、米国のそれは、子供達向けのイベントで、仮装した子供たちが近所の家を訪れては「Trick or treat（イタズラをされたくなければお菓子を頂戴）」と言ってお菓子をもらいます。

このイベントに参加している家は、玄関口にカボチャを置いて、参加を表明するしきたりになっていますが、中にはこだわって、ガイコツ・魔女・蜘蛛の巣などを前庭に飾って、子供たちを驚かせたり喜ばせたりします。

私のシアトルの家の近所でも、すでにこんな飾り付けが始まっており、紅葉と合わせて街全体が「秋景色」になっています。



AIネイティブな時代のUI/UX

OS(オペレーティング・システム)やアプリケーションのUI/UX（ユーザーインターフェイス/ユーザー体験）を考える際に、マン・マシン・インターフェイス(MMI)やヒューマン・コンピュータ・インターフェイス（HCI）という言葉が使われます。「人とコンピュータの間のインターフェイス（やりとり）」を表すからです。

しかし、進化し続ける「自然言語が理解できる言語モデル」の存在を前提としたOSやアプリのデザインを考える際には、この「人とコンピュータの間のインターフェイス」という見方だけでは不十分だと考えるようになりました。

ソフトウェアを開発する際には、最近は、CursorというIDE（ソースコードエディター）を立ち上げて、その中でClaude Code(やCodex)を立ち上げて開発する、という手法を採用していますが、その感覚は、もう一人のエンジニアとペア・プログラミングをしている感覚に似ています。

大半のコードは、私がClaude Codeに対して指示を出して書かせていますが、たまに私が直接IDEを操作してコードを書くこともあります。私が書いたコードをClaude Codeにレビューさせることもあるし、Claude Codeが書いたコードを私がレビューすることもあります。

つまり、そこには、「人（私）」「AI（Claude Code）」「開発環境（IDE）」の三つが存在し、それらが直接、あるいは、間接的にやり取りをしながら開発を進めて行くのです。

Cursorは、最初にAI機能を持ったIDEとして提供されて評判になりましたが、Claude Codeの誕生により、影が薄くなりつつあります。IDEにAI機能が含まれてしまっているよりは、ターミナル上で動くアプリとしてAIを動かした方が、便利なことに多くの人が気が付いたからです。

つまり、「人」と「AI機能を持った開発環境」という形よりも、「人」と「AI」と「開発環境」という形の方が、使いやすい・心地よい・自然だ、ということです。

これは、UI/UXの観点からとても重要です。人間は、プログラミングに限らず何らかの作業や操作をする時には、「どんな操作をしたらばどんな動きをするか」をしっかりと理解する必要があります。自動車であれば、アクセルを踏めば加速し、ハンドルを右に切れば右折する、などです。

しかし、そこに第三者が絡む際には、大きく変わってきます。タクシーに乗っている際には、直接ハンドルやアクセルは操作せず、運転手さんに対して行き先や道順を指示するだけです。

つまり、自らが自動車を運転する際には、「人と自動車」がインターフェイスを持つだけですが、タクシーに乗る際には、「乗客と運転手」「運転手と自動車」という二つのインターフェイスが存在することになります。

このモデルに照らし合わせると、Claude Codeを使ったコードを書くことは、「乗客」である私が「運転手」に相当するClaude Codeに自動車を運転させつつ、時々、ハンドルやアクセルを直接操作しているという三つ巴のインターフェイスが存在しています。

私がオープンな形で開発しているMulmoChatも同様で、「ユーザー」と「AI」が音声を通じたインターフェイスでコミュニケーションを取りながら、AIがファンクション・コールを通じて必要な機能（アプリケーション）を呼び出す設計になっていますが、アプリケーションとユーザーの間はGUIを通じた直接的なインターフェイスもあるため、同じく三つ巴のインターフェイスになっています。



そう考えると、「自然言語を理解する言語モデル」は、UI/UXの観点から言うと特殊な存在であり、「マシン」としてひとまとめにしてしまうよりは、タクシーにおける運転手のような存在として扱った方が、自然で分かりやすいように私には思えます。

つまり、従来型の「マン・マシン」インターフェイスという考え方から、人とAIとマシンが三つ巴のインターフェイスを持つ、「マン・マシン・AI」インターフェイスという見方をした方が、AIネイティブなOSやアプリの設計をする際には適しているように思えるのです。

AIが置き換えるべき市場

シンギュラリティ・ソサエティとして書かれた記事「AIが「人件費の構造」を変える時代、プログラマー起業家が狙うべき市場」ですが、とても重要なことが書いてあるので、是非ともお読みください。

最も重要な点は、ビジネス全体の経費を見た場合に、「人件費の比率が高い業種ほど、AIの導入によるコスト削減効果が大きい」という点です。

記事でも指摘されている、コンサルタント、受注スタイルのソフトウェア会社などが良い例です。これらのビジネスは、これまでのやり方だと、ビジネスの規模を大きくするためには大勢の人を雇う必要がありますが、それによって固定費（売上があろうがなかろうが出ていくお金）が高くなるため、そこには大きなリスクが伴いました。

AIの力を使って、従業員の数を増やさずにより多くの仕事をこなせるようになれば、固定費を増やさずにビジネスの規模を大きくする（＝売上を増やす）ことが可能になります。

重要な点は、単に「従業員の生産性を上げる」だけの話ではない点です。従業員の生産性を従来の10倍にできれば、従来ならば200人必要だった仕事を20人でこなすことが出来ます。これはこれで素晴らしいことですが、従来ならば2000人必要だった仕事をこなすには200人必要であり、ビジネスの規模が増えるに従って、固定費が増えていくことには変わりがありません。

もっと好ましいのは、ビジネスの規模がいくら大きくなっても、従業員の数（固定費）を増やさなくても良いビジネスです。

「AIをたくさん使えば、API料金や電気代が増えるから同じだ」と考える人がいるかもしれませんが、これは違います。確かに、API料金や電気代は、ビジネスの規模が大きくなるにつれて増えますが、売上に応じて自動的に増えたり減ったりする変動費なので、（簡単に下げることができない）固定費となってしまう人件費とは大きく違うのです。

特に日本の場合、「正社員を簡単には解雇できない」という雇用規制があるため、固定費を低く抑えながらビジネスの規模を大きくすることがとても重要です。これまでは、必要に応じて子会社や孫会社に仕事を回す、というゼネコンスタイルや、（解雇しやすい）派遣社員などの非正規社員を増やす、などでしのいできましたが、これからは、AIが「固定費を増やさずに売上を増やす」面でとても重要な役割を果たすと考えられます。

とは言え、普通の企業にとってAIを使いこなすことは簡単ではありません。そこで必要とされるのは、企業が必要とする仕事を人の代わりに実行してくれるAIをサービスとして提供する会社です。

その際に、顧客である企業にとって重要な点は、「人より安い」ことではなく、人を雇うことにより生じていた「固定費」をAIを使うことにより「変動費」に変えることができる、という点であることは強く意識しておくと良いと思います。

OpenAIとBroadcomの契約

OpenAIが、NVIDIA、AMDに続いて、Broadcomとの契約を発表しました（参照：OpenAI and Broadcom announce strategic collaboration to deploy 10 gigawatts of OpenAI-designed AI accelerators）。

OpenAI独自のAIチップ、およびそれを使って構築するAIデータセンターをBroadcomの協力を得てデザインし、2026年から2029年にかけて10GW分構築するというものです。

OpenAIは、NVIDIAと10GW、AMDと6GWのAIデータセンターを構築することを約束したばかりなので、一見すると「節操がない」ようにも見えますが、AIへのニーズが今後さらに伸びると確信しているOpenAIとしては、

NVIDIA一社に依存はしたくない、AMDと競合させることにより価格を下げる圧力をかけたい。
Googleのように独自ASICを持ち、それによりさらに価格を下げたい。さらにスピードなどで差別化したい。
一社が頼ったためにそこがボトルネックになることを避けたい
たとえアーキテクチャが分散しても、莫大な計算資源が欲しい
アーキテクチャの違いは、Tritonで吸収できる
Tritonとは、OpenAIがオープンソースな形で開発しているGPUのプログラミング言語です。CUDAのように特定のアーキテクチャに縛られずにGPUプログラミングが出来る上に、アーキテクチャごとに必要な最適化はTritonが行ってくれるため、プログラマーはGPUに関する専門知識がなくても、高性能なGPUカーネル（GPU上で実行される小さなプログラム）を作ることが可能だそうです。

OpenAIがTritonを発表したのは2021年で、当時はNVIDIAのGPUしかサポートしていませんでしたが、今では、AMDやIntelのGPU向けの開発も進んでおり、OpenAIとしては、Tritonを活用することにより、異なるアーキテクチャのAIデータセンターを使いこなせると考えているのでしょう。

Introducing Triton: Open-source GPU programming for neural networks
「AIブーム」と「AIバブル」

上に書いたように、OpenAIが巨大なAIインフラ投資の契約を結ぶにつれ、NVIDIA、AMD、ASML、TSMCなどの半導体会社への期待が膨らむのは当然として、Oracle、Coreweave、Nebiusなどのインフラ企業への期待が高まり、株価が高騰しています。

しかし同時に、「これはバブルか」「そろそろピークか」などという声もあり、結果として、これらの株価は、ちょっとしたニュースで乱高下を繰り返す状況になっています。

ちなみに、私は今回の「AIブーム」は一過性のものではなく、近い将来にはAIが「電力」や「水道」のように、社会を支える重要なインフラの一部になると確信しています。

だからと言って、今の株高が、2000年のインターネットバブルのように一時的に弾けることはない、とは思っていません。赤字を垂れ流して成長していた企業が突如倒産したり、莫大なインフラ投資をしていた企業が借金が返せなかったり、などの嵐が吹き荒れる可能性は十分にあります。この手のブームは、そんな一時的な「バブル崩壊」を経た後に本格的な成長をするのが当たり前だからです。

インターネットバブルの際には、バブルの真っ只中に世界中に光ファイバーのネットワークがインフラとして張り巡らされ、バブルの崩壊と共に、そこに先行投資をしていた数多くの会社が倒産しましたが、その時に作られたインフラが、その後のインターネットの発展の礎となりました。

同様のことが、AIに関して起こる可能性は十分にありますが、一つだけ違うのは、インフラの寿命です。

光ファイバーの技術も進化をし続けているとは言え、進化のスピードはそれほどでもないため、一度構築された光ファイバーネットワークは、長期間使用されるため、会計上の償却期間は20～30年という長期に渡るものになります。仮に20年とすれば、毎年、投資総額の5%を経費として計上することになります。

AIインフラの場合、GPUの進化のスピードが早いので、償却期間は5年程度です。つまり、投資総額の20%を経費として計上する必要があり、売上がそれを超えない場合には、赤字決済になります。

この違いが意味することは二つあります。一つ目は、AIインフラ投資は光ファイバーへの投資と違って、すぐに結果を出す（売上を上げる）必要があるということです。光ファイバーのように償却期間の長いインフラであれば、投資家も長い目で見てくれるので、最初の２～３年は赤字でも、順調にビジネスが成長していれば大丈夫です。しかし、AIインフラの場合、最初の１～２年で黒字を計上できないと、投資家から見放される可能性が高くなります。

二つ目は、「バブル崩壊後」のAIインフラの価値です。光ファイバーはインターネット・バブル崩壊後も、それを手に入れた人たちに大きな利益をもたらしましたが、償却期間の短いAIインフラは、すぐに資産価値が下がってしまいます。

AIインフラの場合、電源や冷却のための水が重要な役割を果たすため、それらが安定して確保できる場所の確保が簡単ではなく、それが成長のボトルネックになると言われています。場合によっては、新たなデータセンターを建てるよりも、既存のデータセンターをアップグレードした方が良いケースも出てくると考えられ、その際には、償却前のGPUを外して最新のGPUに置き換える、などの措置が取られることもあると思います。

ちなみに、NVIDIAは、以前は2年ごとに新しいGPUをリリースしていましたが、2024年からはそのサイクルを1年に縮めると宣言しました。さらに、NVIDIAはGPUを進化させるだけではなく、ネットワークも含めたAIサーバー全体で性能を向上させる戦略に出ており、それがAIインフラの償却期間をさらに短くしてしまう可能性は十分にあります。

私は、以前にも、MicrosoftがOpenAI向けのインフラビジネスの一部をOracleに譲ってしまった点に注目して来ましたが、償却期間の短いAIインフラに対して大きくコミットすることは、Microsoftのような巨大企業にとってもリスクが大きすぎるからだ、と解釈して良いと思います。

私の目に留まった記事

当社は今年の7月1日をもって株式会社安川電機の完全子会社となりました。

東京ロボティクス株式会社という人型ロボットを開発しているベンチャー企業が、安川電機により買収されたことを報告するXへの投稿です。

東京ロボティクスについては、過去に何度か目にしたことがありますが、直感的にはとても良い買収だと思います。リスクマネー（ハイリスク・ハイリターンなベンチャー企業に積極的に投資するお金）が少ない日本においては、この手のベンチャーが独立したままで成功することは難しく、こんな風に既存のビジネスを持つ会社に買収された上で、その会社の成長戦略を担うというのはとても理にかなっています。

安川電機は、大正時代（1915年）に炭坑用電気機器（モータなど）を受注生産する事業としてスタートした老舗で、戦後・高度成長期を経て、モータから、電子制御を取り入れた機電融合（メカトロニクス）への進化を図って来た会社です。

1970年代以降は、産業用ロボット事業（ブランド名：Motoman など）にも進出し、現在では、FANUC、EPSON、川崎、デンソーと並んで大きなシェアを持つ日本企業の一つで、世界市場の約８％を握っていると言われています（参照：The World’s Top Industrial Robotics Companies by Market Share）。



今後、安川電機が、この買収をどう活用するか楽しみに見て行こうと思います（注：私は、安川電機の株は持っていません）。

OpenAI’s Growing Ecosystem Play

OpenAIが、サードパーティのウェブサイトにChatGPTのアカウントでログインし、そこからOpenAIが提供するAPIを（ユーザーのアカウントを使って）使えるようにする機能を提供する予定であることを伝える、The Informationのリーク記事です。

まだリーク記事の段階でしかありませんが、私のような開発者にとってはとてもありがたい機能です。私自身、MulmoCast、MulmoChatとさまざまなAI機能を活用したアプリを開発していますが、APIの従量課金がある限りは、無料で提供することは難しく、ユーザーにAPIキーを取得してもらうという面倒なことをお願いしなければなりません（先週リリースしたMulmoCastはそんな設計になっています）。

OpenAIがこの仕組みを提供してくれれば、MulmoCastをWeb上のサービスとして提供し、利用者には、ChatGPTのアカウントでログインしてもらった上で、そのユーザーの権限で、LLMや画像生成のAPIを使わせてもらいます。それにより、こちらは運営コストを極端に抑えられるため、サービスを無料で提供することが可能になるし、APIキーを取得するなどと比べると、敷居が大きく下がることになります。

使えるAPIは、OpenAIのものに限定になりますが、それだけでもやれることは十分にあります。

OpenAIがこのサービスを提供し始めると、「ChatGPTでのログイン」がAIサービスのデファクト・スタンダードになってしまい、GoogleやAnthropicは非常に厳しい戦いを強いられることになります。

そう考えると、Googleこそこんな機能を提供すべきと思えますが、GoogleはOpenAIのように一枚岩ではないので、実現はとても難しいだろうと想像できます。

BlackRock, Nvidia, Microsoft, and xAI have formed a consortium to acquire Aligned Data Centers for $40 billion, according to the Financial Times.

Nvidia、Microsoft、xAIの三社が資産運用会社のBlackRockとコンソーシアムを組み、米国と南米に５０ヶ所のデータセンターを持つ Aligned Data Centers という会社を $40billion で買収するという報道です。

この会社は今後、毎年20GWのペースでAIデータセンターを新設し、パートナーであるMicrosoftやxAIは当然のこととして、OpenAI、Google、Metaなどにリースするそうです。

AIが社会のインフラとなりつつある中、当然の動きですが、今後、巨額な設備投資が行われる中で、「誰がどんなリスクを背負っているのか」を理解することはとても重要です。

この会社が担当するのは、土地、電力、水、建物であり、そこが、MicrosoftやxAIなどの顧客に対しての建物をリースし、その上にGPUなどから構成されるAIサーバーを構築するのは顧客の責任になります。上に書いたように、GPUの償却期間は5年程度ととても短いですが、建物の方は20年以上かけて償却されるため、それぞれのビジネスリスクは大きく異なるものになります。

AIデータセンター向けの電力の確保が課題になりつつある今、このレイヤーのビジネスがとても重要な役割を果たすことになるのです。

エヌビディアの資産活用…スパコン富岳の後継機、日米共同開発が果たすべき使命

理化学研究所のスパコン「富岳」の後継機「富岳ネクスト」を富士通と米エヌビディアを含む３者で開発することになったことに関する解説記事です。

以前は専用のCPUで作られていたスーパーコンピュータは、汎用化の波に押され、今ではほとんどのスパコンは、市販のCPUやGPUを組み合わせることによって構築されています。記事の中で紹介されているスパコン性能ランキングを見ると、富岳以外の全ては、Intel、AMD、NVIDIAのいずれかの会社のCPUとGPUにより作られています。

今回のアナウンスメントは、ひとことで言えば、独自路線を走って来た理研・富士通も、この流れには逆らえず、CPUのみは独自のものを使い続けるものの、GPUに関してはNVIDIA製のものを使うことになった、という話です。

今後、スパコンの利用目的の大半がAIの学習や推論になることを考えれば、このまま独自路線を走っても研究者が使いたがらないので、AI研究者の間で広く使われているCUDAが活用できるNVIDIA製のGPUを搭載することは理にかなっています。

その場合、CPUがやることはPythonインタープリタを実行して適切なデータをGPUに渡すことぐらいなので、どこのCPUであっても大差はなく(＝富士通の独自のCPUであっても研究者は困らない)、それよりも、いかにCPUとGPUを上手に繋げてデータ転送にかかる時間や電力を減らすかが勝負になります。

しかし、そこに関しては、NVIDIAが既に莫大な研究開発費を投じて開発をしているので、そのままNVIDIAのサーバーを購入した方が、大幅に時間が節約できると思いますが、それでは富士通の存在意義がなくなってしまうので、こんな形になったのだと解釈できます（xAIは、わずか数ヶ月で、100,000基の Nvidia H100 GPUで構成される巨大なAIデータセンター「Colossus」を構築しました。スパコンのランキングを決めるTOP500に参加しているわけではありませんが、1～2EF(exaflops)を持つ計算能力は、一位の「El Capitan」に相当します）。

日本政府としては「日本独自の技術力を育てる必要がある」という考えなのでしょうが、まずは「富士通がどこで勝負する会社なのか？」という問いにしっかりと答えた上で、税金を投じるべきだと私は思います。富士通がAIサーバー向けのCPU市場で戦ったり、AIサーバー・インフラ企業として勝負をかけるつもりならば構いませんが、単に「スパコン・ランキンの上位にい続けたい」「せっかく富岳向けに作ったCPUの資産を生かしたい」程度の理由であれば、説得力に欠けます。

ちなみに、最近はAIデータセンターの規模は、GW（ギガワット）と電力の単位で示します。Colossusの規模が0.5GWほどなので、「0.5GW = TOP500のトップクラスのスパコンと同等の計算能力」と考えて良いと思います。OpenAIは、NVIDIAと10GW、AMDと6GW、Broadcomと10GWのAIデータセンターを構築することを発表したばかりですが、その計算能力は、その50倍以上になる計算になります。

このように、汎用チップや汎用サーバーを使ってスパコンを構築する時代は、スパコンの能力が資金力で決まる時代でもあるわけで、スパコンのランキングを決める「TOP500」の意義が薄れつつあるとも言えます。

民主党政権時代に、蓮舫議員がスパコンに関して｢2位じゃダメなんでしょうか｣と発言したことが話題になりましたが、今であれば「資金力さえあれば上位に食い込めるTOP500に、そもそも意味があるのでしょうか？」「富士通のCPUなど使わずに、NVIDIAのAIサーバーを構築しただけじゃダメなんでしょうか｣という発言になるでしょう。

【参考資料】

RIKEN, Japan’s Leading Science Institute, Taps Fujitsu and NVIDIA for Next Flagship Supercomputer
Fujitsu and Nvidia to co-develop AI systems for next-gen manufacturing
世界一のスパコン「富岳」、「２位じゃダメなんですか」への科学者の答えだった…２００９年１１月［あれから］＜３０＞
The Art of Scaling Reinforcement Learning Compute for LLMs

先週、斜め読みした論文の一つです。DeepSeekの成功以来、大規模言語モデル（LLM）の性能を向上させる際に強化学習（RL）を使うことに注目が集まっていますが、この論文は、強化学習による性能向上の仕組みを40万GPU時間(コストは$4.2million、約6億円)を使った大規模な実験を通じて、RLによるLLMの性能向上をモデル化する枠組みを提案しています。

「RLによるLLMの性能向上をモデル化」できれば、LLMをRLを使って強化する際には、どこで、どうやって、どのくらいの計算量を費やすのが適しているのか、などが前もって明らかになります。LLMの規模が大きくなるに従い、その学習コストは日本円で数十億円～数千億円という天文学的数字になっており、性能向上に効果がある部分だけに集中して時間（＝コスト）をかけたいのは当然の話です。

地味な研究ですが、この手の研究をしっかりとすることが、今後のLLMのさらなる性能向上に重要な役割を果たします。

こんな論文を目にするたびに、私は研究者ではなく、彼らが作ってくれた技術でアプリケーションを作るエンジニアが向いていると、つくづく思います。

https://alexzhang13.github.io/blog/2025/rlm/

これも、先週目を通した論文の一つですが、一つ上の論文と違って、LLMそのものを改良する話ではなく、既存のLLMの上に、Pythonで構築した制御レイヤーを構築して全体としての性能を上げる話なので、はるかに理解しやすいし、仕事にも直結する話です。

最近のLLMは、大きなコンテキストを処理できる（＝長い文章を含んだプロンプトを処理できる）ようになりましたが、コンテキストが大きくなると性能が落ちてしまうことが問題です。

この論文の筆者は、LLMの上にPythonで制御レイヤーを被せ、ここで再起的にLLMを呼び出すことにより、大きなコンテキストの処理に成功したそうです。

この制御レイヤーの役割を簡単にまとめると、

テキストの一部を「peek」してざっと把握する
必要そうな部分だけ「grep」して抽出する
部分ごとにサブタスクを作り、再帰的にLLMを呼び出す
結果を統合して出力を生成する
というものだそうです。

一の部分にLLMを使ってしまうと意味がないので、ここに関しては、章の切れ目などを活用してPython側で行うようですが、この手法は、RAG(Retrieval-Augmented Generation)とも密接に関連する、とても重要な話をしています。

RAGは、長い文章を「チャンク」に分割し、それぞれのチャンクをEmbedding Vector化した上で、ユーザーからの質問のEmbedding Vectorと似たチャンクだけを拾い出してコンテキストとしてLLMに与える手法です。

それに対して、この手法は、質問がされた時に、元の文章の中から関連する部分を抜き出し、かつ、部分ごとにサブタスクを作って再起的にLLMを呼び出すという手法をとっており、RAGと比べると計算時間もコストも大きくなってしまいます。

私がこの論文をシステム作りに役立てるとすれば、この論文のアイデアを活用し、

前処理では、全体の要約、章ごとの要約、および、それぞれの章の内容に応じたキーワードのインデックスのようなものを用意する
実行時には、前処理したデータをすべてLLMに与えた上で、どの章を読みたいか（複数）を指定させる
そして今度は、全体の要約と、指定された章をひとまとめにしてLLMに渡して質問に答えさせる
のようにするだろうと思います。

従来型のRAGと最も異なる点は、「どの章を読むべきか」をLLMに判断させる、というプロセスですが、LLMが十分に賢くなったからこそできるようになった手法です。

Some golden nuggets from an interview with a former $GOOGL employee on TPUs and the future of Search

元Googleのエンジニアのインタビューから、重要な部分を抜き出したXの投稿です。この投稿によると、

Googleは既に推論に関しては、NVIDIAへの依存から脱却し、自社製のTPUを使っている
Googleの技術スタックは、既にTPUに最適化されている。
Googleは、TPUを使うことにより、推論コストを大幅に下げることに成功している
Googleは、サードパーティにTPUを提供することにより、TPUのエコシステムを大きくしようとしている
Googleは、AIと広告ビジネスの融合に真剣に取り組んでおり、成功しつつある。
AIサービスにおける広告の単価は、検索のそれよりも高くなる可能性がある。
ChatGPTやPerplexityが出てきた時には、私も含めて多くの人が、これらのAIサービスがGoogleの検索ビジネスを破壊すると予想していましたが、現時点ではまだ破壊されておらず、Google自身も、徐々に（広告ビジネスを破壊せずに）検索をAIで置き換える準備を進めているように思えます。

しかし、人々がGoogle検索の代わりにChatGPTを使うようになりつつあることは事実であり、Googleとしてはその流れを止め、AIとのチャットもGoogleのサービスを使ってもらうように人々に誘導する必要があります。

米国政府から独禁法で訴えられていたGoogleは、危うくChromeブラウザーの売却を迫られるところでしたが、かろうじて逃れることができました。ここからはそろそろ、ChromeそのものをAIチャットサービスに進化させていくぐらいの大きな変革をすべき時期に来ているように私には思えます。

ちなみに、マルチモーダル・チャット・インターフェイスのMulmoChatのプロトタイプは順調に進んでいますが、次のステップとしては、このチャット・インターフェイスを前面に置いた、MulmoBrowserを開発するのも悪くないと考えています。このブラウザーにおいては、URLバーの代わりにチャット・インターフェイスがあり、そこを通して、LLMと会話をしながら、インターネットをブラウズするのです。ブラウザーにCoPilotがついたイメージではなく、チャットの機能の一つとして、ブラウザー機能があるようなイメージです。

質問コーナー

【質問】

高市早苗さんの総裁選後の「馬車馬のように働いて」「ワークライフバランスは捨てます」の発言が左派メディア中心に叩かれていますが、そもそも政治家は労働基準法の適用対象外ですし、また、それくらいの覚悟で仕事してもらわないと日本の競争力が益々低下していくと思います。また、あくまで自民党の国会議員に向けられた言葉で公務員全般に対して言った発言ではないので全く問題ないと思いました。

中島さんは高市さんのこの発言を聞いてどう思われましたか？

《回答》

高市さんの極端な保守政策そのものは好きではありませんが、この発言そのものは悪くないどころか、好印象を持ちました。政治家にはこのくらいの意気込みで働いてもらわなければ困ります。

【質問】

画像生成のAIサービスについて質問です。Stable Diffusionとnano bananaについて双方の優位性や使い分けはどのようにお考えでしょうか？もし、あまり性能に差がないのであれば無料で使用可能なnano bananaの方が優秀ということになりますか？

《回答》

今のようなスピードで進化が起こっている場合、「どちらが優秀」という議論にはあまり意味がなく、その時点で自分の目的にとって最適なものを選ぶしかありません。私は、現時点ではnano bananaを主に使っていますが（APIなので、有料です）、一番の理由はスピードです。特に開発している際には、生成スピードは、開発スピードに直結するので、最も重要なファクターの一つです。

無料枠で遊びたい人たちにとっても、nano bananaは現時点ではとても魅力的なものだと思いますが、それも１～２週間の間に変わってしまう可能性は十分にあります。

【質問】

自分のYouTube動画を海外にもリーチさせたい場合、タイトルを英語にするだけで十分でしょうか？もしくはサムネイルも日本人と外国人とで好みが違いますか？YouTubeの内容はガンプラを作成するようなエンタメ系です。

《回答》

確かに好まれるサムネイルは日本と米国ではかなり違うので、英語圏で視聴数の多いビデオのサムネを参考に工夫するのが良いと思います。ちなみに、Youtubeには「最適解」のようなものはなく、実際にコンテンツを出していく過程で色々と試してそこから学び続けることが大切です。どんなに一時的に流行ったチャンネルでも、この「学び続ける」姿勢がなければ、人は離れていってしまいます。

【質問】

日本の大手メーカーに勤める者です。SDGsというワードが生まれてから久しいですが、以前に比べこの言葉を聞かなくなった気がします。何となくですが、生成AIの技術話題が出てきてから、SDGsのワードが掻き消されている気がしています。

表現の仕方が難しいですが、話題(例えば技術革新や大災害・戦争など)がないと暇になり、SDGsのような環境話題を提起してくる団体が現れるのではないかとも感じています。そういった指標に振り回されることは果たして正しいのかつくづく疑問に感じますが、中島さんの意見を聞かせていただければと存じます。

《回答》

生成AIの話題が増えたため、相対的にSDGsへの注目度が減っているように見えるだけです。SDGsは、決して一過性のものではなく、継続的に意識しておくべきものです。

ちなみに、トランプ大統領は、SDGsのような問題を軽視する人であり、かつ、「SDGs=左翼」というイメージが作られてしまっているために、予算も削られてしまっているし、米国が「パリ協定」から離脱してしまっています。SDGsの件は、本来はイデオロギーとは独立した話なのに、トランプ氏や彼の支持者たちは、そうは考えていないようです。

【質問】

私は現在50歳で、動画編集の仕事を約25年続けております。

ここ数年で仕事の流れが大きく変化しており、企業の紹介ビデオ（16:9）のような従来型の案件が減少し、縦型動画やSNS向けのコンテンツの需要が急速に増えてきております。

これまでに生成AIを活用した簡易な動画制作は数本ほど行ったことがありますが、本格的にこの分野の知識を深め、今後のキャリアに活かしていきたいと考えております。

つきましては、以下の2点についてご教授いただけないでしょうか。

今後、動画編集者として活かせるAI関連の資格には、どのようなものがあるでしょうか？個人で受験を検討しており、予算としては1万～2万円ほどを想定しています。
生成AI動画やAI活用に関して、無料で安全に学習できるおすすめの方法やサイトがあればご紹介いただけないでしょうか？基礎から実践まで幅広く学びたいと考えております。
長年動画編集に携わってきた身として、時代の変化に柔軟に対応していきたいと考えております。

《回答》

そもそも、その手の「資格」には意味がないだけではなく、情報弱者を狙い撃ちにした「情報商材ビジネス」の一環として提供されることが多いので、避けた方が良いと私は思います。

この手の新しい技術を勉強するには、実際に自分で手を動かして色々と試すのが一番です。授業を受けたり、参考書を読んで勉強するものではありません。例えば、GoogleのAI Studioは、画像生成（nano banana）や動画生成（veo3）が無料で試せるので、活用すると良いと思います。

私が、先日公開したMulmoCastを使えば、脚本から動画を生成することも可能なので、是非ともお試しください。

【質問】

よく紹介される銘柄を中島さんは少し買ってますとかおっしゃいますが、中島さんの少し買ってますがデカすぎて、もしかしたら私の資産と同じくらいなのかなと考えてしまいます。中島さんくらい資産を持っているとドルコスト平均法で買うのがいいと思いますが、私みたいな弱小個人投資家の場合はなかなか虚しいですが、結果的にはドルコスト平均法が一番割に合うんでしょうか。少し買ってます。は、何株くらい買っているんですか？

《回答》

株はさまざまな理由で乱高下するので、そのノイズを除去するには、ドルコスト平均法が一番です。私が、「この会社は面白そうだから、少し株を持って自分ごとにしてみよう」と考えた場合に購入するのは、多くの場合5,000ドル程度です（小さな会社の場合は2,500ドルにすることもあります）。株数ではなく、ドルで考える背景には、ドルコスト平均法があります。その後、経過を見て、もう少し買い増そうと考えた時にも、（株価が上がっていようが下がっていようが）やはり5千ドル分購入します。

【質問】

私はAIを用いた医療画像診断システムの開発をしているエンジニアです。今までは実際に手を動かしてコードを書く仕事をしてきたのですが、今年で29歳になることも踏まえ、より上流の設計やプロジェクトリーダーのような仕事をしたいと考えています。

チームリーダーになるには、ある課題に対して自ら仕様や納期を決めたり、市場で発生した不具合に対応したりと製品に対して大きな責任を持つ必要があるのですが、個人的に製品の仕様を決めたりスケジュールを決めたりといった不確実な未来に対して予め決断をすることに苦手意識を持っています。普段の仕事でも、一度決めた開発方針からブレることが多く、未来の事象に対して素早く決断できていないと感じることが多いです。個人的には、たとえば大がかりな開発のスケジュールを組むとすると「未来のことなんて分かんねーよ」という気持ちになってしまいます、、笑

また、自分自身社会人になってからエンジニアになったこともあり、周りと比べてコンピューターや関連分野に関する知識のなさを痛感しており、そのことがより判断を遅くしてしまっているように感じます。日頃から仕事に関する勉強はしているのですが、優秀なエンジニアの方々は確かな技術力や知識があるので判断が必要なタイミングである程度先が見えていて方針を決めているのか、それとも分からないことはあるけれども腹を括ってえいや！と決断しているような感覚なのでしょうか？

中島さんご自身、開発において将来の指針を決めなければいけないときにどのような思考回路で行動されているかお聞きできれば幸いです。また、今まで共に働いてきた方々のなかで大規模な開発の要件定義、設計、スケジューリングなど将来の指針を決断する場面でなにか印象に残るような行動を取ったエピソードがあればお聞きしたいです。

《回答》

結構深い話ですが、簡単に言えば、「大きな流れに関しては、ちゃんと考えた上で」「細かなことは深く考えずに、まずは手を動かす」です。

具体的には、「これからはAIが世の中を変える」という話は大きな流れで、「LLMのAPIは、OpenAI、Anthropic、Googleのうちどこを使うべきか」は細かな話です。

エンジニアも含めて、多くの人が「細かなこと」を決められずにいつまでも議論したり、立ち止まったりしていますが、私はとてももったいないと感じています。「細かなこと」は「エイやっ」と勘で決めて、途中で間違っていると気がついたら修正をすれば良いだけの話です。

これは以前から私が指摘している話ですが、「自分が進んでいる道が正しいかどうか」はある程度進んでみないと見えてこないものです。なので、いつまでも分岐路で悩んで立ち止まっているのではなく、とりあえずどちらかに向かって進んでみるのが一番の近道です。

その際に、「細部にはこだわらず、まずは形にしてみる」こともとても重要です。最初から、細部にこだわって作ってしまうと、たとえ途中でその方向性が間違っていると気がついても、そのコスト（いわゆるサンクコスト）が重荷となって、「捨ててやり直す」ことが難しくなってしまいます。

【質問】

お忙しい中すみません。なぜヒト以外の動物には知性がないのでしょうか？最近のAIの進化を見ていると、ヒトとヒト以外の動物に本質的な違いがあると言う合理的な説明は、一体何なのだろうかと思います。

また、クジラは、広大な海洋の中で音波を使って「会話」をしており、ヒトの知性や言語とは違うが、自動学習のプログラム次第では、クジラ型AIも可能になるのでしょうか。　ホーガンの『未来の二つの顔』を読んでいて思いつきました。ホーガンは、ヒトが万物の霊長であるとのキリスト教的世界観を前提にしています。日本人的な八百万の神という世界観では、全く違ったSFの世界観も可能なのではないかと思いました。

《回答》

私は、ヒトの脳とそれ以外の動物の脳に本質的な違いはないと考えています。唯一の違いは、シナプスやニューロンの数で、数が多いからゆえに可能になったことがたくさんあるだけの話です。

この考え方で言えば、犬や鯨にも知性があるのは当然ですが、では、蚊とか山椒魚に知性があるのか、という話になると、そもそも「知性とは何か」「自我とは何か」という所に立ち戻らなければならなくなり、さらに「AIに知性はあるのか」「AIに自我が生まれる可能性はあるか」という話になってしまいます。

ご指摘のとおり、キリスト教には「ヒトは特別な存在である」ことを前提に作られた宗教であり、西洋にはそれをベースに「知性」や「自我」の議論を展開する人が多いので、ちょっと厄介です。「ヒトは単にサルから進化しただけの存在で、脳の構造に本質的な違いはない」と発言しただけで、「キリスト教を否定する」発言と見なされてしまうからです。

その意味では、そんな「しがらみ」を持たない日本人の方が、「AIに自我が生まれるとは何か」という議論を、客観的・科学的に展開するのに適しているのかもしれません。

【質問】

私は国内で動物病院の経営をしております。

海外でお住まいの経験が長い中島さんにお聞きしたいのですが、動物病院が配る無料のアメニティで印象に残ったものや、マーケティング戦略として行っているサービスで印象に残ったものがあれば教えて頂きたいです。

《回答》

犬を長年飼っていたので、動物病院には世話になりましたが、特にアメニティをもらったことはないし、マーケティング戦略として印象に残ったものもありません。唯一印象に残っているのは、私たちのことを「飼い主」とは呼ばずに、「親」と呼ぶ点ぐらいです。最初は違和感を感じましたが、どの動物病院でもそうでした。

【質問】

オープンソース文化の象徴でもあるArduinoを、クアルコムのような巨大半導体企業が買収したことに驚きました。しかも、王道モデルである「Arduino Uno」の名前を引き継いだ新モデルには、賛否が分かれそうです。

今回の買収には、どのような戦略的意図や狙いがあるとお考えでしょうか。

《回答》

この件（A new chapter for Arduino - with Qualcomm, UNO Q, and you! ）ですね。

Qualcommが買収した理由も分かりますが、全てがオープンだったからこそ普及したArduinoが、今後、どんな発展をするのかは不明です。

Qualcommとしては当然、自社製のチップをArduinoのデファクト・スタンダードにするつもりでの買収ですが、それをコミュニティがすんなりと受け入れるとは考えにくいのも事実です。

今では、オープンソースなRISC-Vという選択肢もあるため、結果として、Arduinoに変わるRISC-Vベースのオープンプラットフォームを作ろうとする動きが加速する可能性も十分にあります。

私がQualcommの担当者であれば、どうやったら「Qualcommの買収によりArduinoはより良いプラットフォームになった」と思ってもらえるかを真剣に考え、コミュニティの声に真摯に耳を傾け、最初は採算度外視でより多くの人に、新モデル（UNO Q）を使ってもらうかを最優先するだろうと思います。開発者コミュニティが離れてしまっては、買収した意味がなくなってしまいます。

【質問】

ビル・ゲイツは、2025年のインタビューで「今後10年以内に、医師や教師といった専門職の多くがAIに代替されるだろう」と予言したそうですが、ＡＩの進歩に鑑み、中島さんは、何年くらい後に、医師や教師のような知識労働者が、ＡＩとロボットに代替されるとお考えでしょうか？　また、ＡＩとロボットに、殆どの労働者が代替されるようになったら、ベーシックインカムを配るか、社会主義経済にするか、あるいは、別の対策をとるか、どのようにして、社会の安定を実現したらよいとお考えでしょうか？

《回答》

既に、米国では、医師や教師のような知的労働者のAIによる置き換えは始まっています。まずは、（既存の従業員の）生産性の向上、アウトソースコストの削減、採用見送り、などの形から始まるため、すぐに数字としては見えて来ませんが、この傾向は、3～5年ではっきりとした数字で表れ、10年後には、労働市場の在り方が大きく変わっている、と私は見ています。

患者や生徒の心のケアのような仕事は、まだ今のAIには任せられませんが、CTスキャンの画像から診断する、生徒一人一人の理解度に応じたテキストや演習問題を作る、などの作業に関しては、AIの方が既に優れているし、コストも圧倒的に低いからです。

AIとロボットがほとんどの労働をやってくれる社会において、人間は何をすれば良いのか、職のない人たちをどうサポートするのか、「生きがい」をどうやって見つけてもらうのかは、とても深刻で重大な問題であり、今のうちから十分に議論をし、法整備をして備える必要があると私は考えています。

最終的には、ベーシックインカムに相当するような仕組みを提供することにより、AIとロボットがもたらす価値を国民全員で享受する形が理にかなっていますが、「誰もが他人の役に立つことをすること」で成り立って来た社会を、どうやって維持すべきなのかの回答は誰も持っていないと私は思います。

AIに「危機感」を持つ人の多くが、AIによる世界制覇などを心配しているようですが、大半の人が「働く生きがい」を無くしてしまった社会をどうやって維持するかの方がずっと現実的で、かつ、危機的な問題だと私は思います。
