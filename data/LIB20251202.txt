週刊Life is beautiful ２０２５年１２月２日号：Google vs. OpenAI、生成AI時代の働き方、MulmoChatを使ったLLMのベンチマーク

今週のざっくばらん

Google vs. OpenAI

ここ数カ月、Googleが立て続けに強力なモデルを出してきています。大規模言語モデルの Gemini 3、画像生成モデルの Nano Banana Pro など、「ようやく本気を出してきた」という印象を持った方も多いのではないでしょうか。

なぜ Google は出遅れて見えたのか

OpenAI が ChatGPT を公開して一気にユーザーを集めた後、Google はしばらくのあいだ「イノベーションのジレンマ」に囚われているように見えました。

検索は「リンクのリスト」を返すだけなので、そこに広告を混ぜればよかった
そのモデルが、Googleの莫大な収益を支えてきた
しかし、ChatGPTのように「回答そのもの」を返すスタイルだと、同じ広告モデルをそのまま適用しづらい
つまり、「技術的にはできるけれど、やれば自分たちの飯の種（検索ビジネス）を破壊してしまう」 というジレンマにあり、動きが鈍ってしまったわけです。

さらに、大企業にありがちな「社内政治」も足かせになっていました。世界トップクラスの研究者を抱える DeepMind と、巨大な収益を生む 検索ビジネス部門 の連携がうまくいかず、せっかくの研究成果がユーザー向けのサービスに落ちてこない、という状態が続いていました。

ChatGPTリリースから約3年が経った今になって、ようやく Google社内の足並みが揃い始めた、というのが現在の状況だと思います。

開発者から見た「Nano Banana」と「Gemini 3」

AIサービスをAPIとして利用する開発者の立場から見ると、Nano Banana の圧倒的な画像生成スピードは特筆に値します。

特に MulmoChat のようなインタラクティブなアプリケーションでは、

OpenAIの画像生成は「遅すぎて体験が壊れる」
「Nano Banana があるからこそ成立するユーザー体験」が現実に存在する
と言ってよいレベルです。

言語モデルに関しても、The Information の記事

Altman Memo Forecasts ‘Rough Vibes’ Due to Resurgent Google

が話題になりました。 Gemini 3 のリリースを受けて、OpenAIのサム・アルトマンは社内向けメモで、

「まだ取り組むべきことはあるが、私たちは急速に追いつきつつある」 ──つまり一度は Googleに先行を許した ことを認めたうえで
「しばらくの間、外部の“vibes（雰囲気）”は厳しいものになるだろう」
と伝えた、と報じられています。

私自身もいくつか試しましたが、Gemini 3 のコード生成能力は非常に高く、シンプルなプロンプトからウェブサイトやゲームを組み立てるのが得意です。これは、単に「便利になった」という以上に、私が以前から指摘している「必要なときだけ一度限り使うコードやUIを生成する時代」への大きな一歩だと感じています。

OpenAI vs Anthropic vs Google ─ 三つ巴の構図

ChatGPT の成功で「最も注目されるAIベンチャー」の地位を得た OpenAI ですが、そのポジションは少しずつ揺らぎ始めています。

コーディング・アシスタントとしては、多くの開発者が OpenAIのCodex ではなく、Anthropic の Claude Code を選び始めている状況であり、私も、

日常のチャットには ChatGPT
コーディングには Claude Code
というふうに使い分けています。

ChatGPTのブランド力とユーザー数は圧倒的ですが、こと開発者向け体験では、その優位がそのまま効いていない のが現実です

結果として、「開発者向けビジネス」に限れば、今年中にも Anthropic の売上が OpenAI を上回るのではないか とさえ言われています（参照：Anthropic Projects $70 Billion in Revenue, $17 Billion in Cash Flow in 2028）。

そこに、Gemini 3 と Nano Banana を引っ提げた Google が、本格的な競争相手として目を覚ましつつある──というのが現在の構図です。

「スケール則の壁」をどう乗り越えるか

ここで効いてくるのが、プリトレーニング（前学習）の進め方の違いです。

近年のAIの進化は、大雑把に言えば、

「パラメータ数・学習データ量・計算量」を増やせば、モデルの能力も伸びる

という スケール則 に支えられてきました。

OpenAI の研究者たちは、この路線にはそろそろ限界が見え始めていると感じ、近年は ポスト・トレーニング（その後の処理）での改良 に力を入れてきた
一方、Google の研究者たちは、 さらに巨大なモデルでもスケール則が効くようなプリトレーニング手法 を追求し、一定の成果を上げた
その結果の一つとして現れたのが、Gemini 3 の高度なコーディング能力であり、それがサム・アルトマンの「rough vibes（厳しい雰囲気）」発言にもつながっているのでしょう
つまり、

OpenAI：「スケールだけではダメだ、学習後の工夫で性能を引き出そうとしている」
Google：「そもそものプリトレーニングのやり方を変えて、もう一段スケールさせることに成功した」
という、アプローチの違いがにわかに可視化されてきた状況です。

体力勝負という現実

さらに厳しいのは、両社の「体力」の違いです。

OpenAI は、いまだに巨額の赤字を垂れ流しながら成長するベンチャー企業であり、 2029年までに累計 $115 billion の赤字を見込んでいると報じられています（参照：OpenAI Says Its Business Will Burn $115 Billion Through 2029）。

一方で Google は、既存ビジネスからのキャッシュフローが潤沢で、 最新四半期だけで $70 billion 規模のキャッシュが入ってくるような企業です。

技術的な競争に加えて、どれだけ長く、どれだけ大きなプリトレーニングを回し続けられるか」という 体力勝負 の側面も無視できません。

Anthropic という新興勢力に加えて、ようやく本気を出し始めた Google── その両方と戦わなければならない OpenAI にとって、これから数年は、技術的にも財務的にも、かなりタフな時間になるだろうと感じています。

生成AI時代の働き方

生成AI時代の働き方については、このメルマガでも何度か書いて来ましたが、参考になる記事を見つけたので紹介します。

NanoBanana Pro時代に考える、AIとデザイン事務所のこれから
読む価値がある部分を抜粋すると。

ひと昔前なら「チームを組まないと回らなかった」ボリュームを、トップレベルのデザイナー 1 人が AI を駆使すれば、物理的には回せてしまう未来が、かなり現実味を帯びてきました。特に、「自分ひとりが暮らしていく分だけ稼げればいい」「小さく、身軽に、好きな仕事だけやりたい」というライフスタイルであれば、「1 人デザイン事務所＋AI」という形は、相性抜群だと感じます。

人件費も固定費も軽い。コミュニケーションコストも最低限。自分の裁量で仕事量もペースもコントロールできる。そういう意味では、AI 時代における一つの理想形として、「1人事務所」はこれからますます増えていくだろうな、と思っています。

となります。しかし、AIを使ったからと言って、クライアントとのコミュニケーションなどの作業は依然として存在し続ける点を指摘した上で、以下のように展開している点も悪くないと思います。

ただ、「中間層がすべていらなくなる」とまでは思っていません。消えていくのは、「作業要員としての中間層」であって、「AIと人とクライアントをつなぐハブとしての中間層」は、むしろ価値が上がっていくはずだと感じています。

と書かれている点も興味深いと感じました。

しかし、これはケースバイケースで、たとえ顧客とのコミュニケーションであっても、人間が必要なケースもあれば、逆にいない方が良いケースがあります。

分かりやすい例が、タクシーとロボ・タクシーです。タクシーの運転手との会話を楽しむ人がいることは理解できますが、ほとんどの人は、ロボ・タクシーを好むだろうと思います。

床屋や美容院になると、人それぞれで、美容師との会話を楽しみながら、髪を切ってもらう時間を楽しむ人にとっては美容師の存在は必須ですが、私のように1分でも早く髪を整えて欲しいと考えている人には、ロボットで十分です。

この記事で取り上げられているデザイナーのような仕事は、顧客が持つ「満足感」「納得感」が結構重要なので、まだまだ人間が活躍する余地がある業界だとは思いますが、「相手の気持ちを読む」ことすら上手なAIが誕生すれば、そこも変わってくるかも知れません。

教育現場でのAIの活用について議論する際には、それぞれの子供に24時間付きっきりで理解度に応じた教え方をしてくれるAIチューターの価値は認めつつも、「子どもたちのやる気」や「子どもたちのメンタル面」に関しては、人間の教師が不可欠だと主張する人が多いですが、それも「EQの高いAI」ができれば解決する話であり、時間の問題のようにも私には思えます。

いずれにせよ、この話は、「これからの子供達には何を勉強させるべきか」「AIが多くの仕事をこなすようになった時に、人間は何をすれば良いのか」というとても重要なトピックなので、このメルマガでも色々な角度から議論して行きたいと思います。

MulmoChatを使ったLLMのベンチマーク

MulmoCast・MulmoChatを開発する際に、今後のAIアプリケーションの発展の鍵を握ると強く感じたのが、LLM（大規模言語モデル）に生成させるべきプレゼンテーション用の言語（Domain Specific Presentation Language）です。

MulmoCastの場合は、映画の台本に相当する「MulmoScript」、MulmoChat上でドキュメントを作らせる際には「拡張Markdown」をプレゼンテーション用の言語として使っていますが、これがとても有効なのです。

先週紹介した、Googleの論文（Generative UI: LLMs are Effective UI Generators）では、HTMLをプレゼンテーション言語として活用していますが、それだとトークンの数が膨大になり、時間がかかるし、LLMに対する要求がとても高くなります。

MulmoScriptやMarkdown程度の言語であれば、自宅のパソコン上で動くオープンウェイトなLLMでも十分に生成できるし、時間もそれほどかかりません。

そうやって色々とテストをしているうちに、これらのプレゼンテーション言語の生成性能をLLMのベンチマークに使うのは、今後、様々なプレゼンテーション言語の応用が増えるだろうことを考慮すると、価値があるように思えて来ました。

まだ完成からは程遠い状況ですが（テスト用のプロンプトが簡単すぎるために、上位モデルの間の差を知ることができません）、途中経過を下に表示します。

Rank	Model	Avg Score	Pass Rate	Perfect Rate	Tests
1	gemini-3-pro-preview	100.0	100%	100%	7/7
1	claude-sonnet-4-5	100.0	100%	100%	7/7
1	claude-3.5-sonnet	100.0	100%	100%	7/7
1	claude-haiku-4-5	100.0	100%	100%	7/7
5	gpt-4o	92.9	86%	86%	7/7
5	gemini-2.5-flash	92.9	86%	86%	7/7
7	gpt-5.1	91.3	86%	71%	7/7
7	grok-4-1-fast-reasoning	91.3	86%	71%	7/7
9	gpt-4o-mini	84.6	71%	57%	7/7
10	ollama-gpt-oss-20b	78.4	71%	57%	7/7
11	ollama-phi4-mini	16.3	0%	0%	7/7
「AnthropicのClaudeの方がOpenAIのGPTよりもコード生成に関しては優れている」という開発者としての感想と良くマッチしていますが、最近リリースされたGoogleのGemini 3が少なくとも同等の能力であることが良く分かります。

私の目に留まった記事

HSBC built a model to figure out if OpenAI can actually pay for all the compute it's contracted.

HSBCによる、OpenAIの財務状態に関するレポートに関するXの投稿です。この投稿によると、HSBCは、

OpenAIのユーザーは、2030年までに30億人に到達（世界の人口の44%）
そのうち10%が有料サービスに課金
OpenAIは、広告市場の2%を獲得
2030年には、売り上げは年間$386 billionに増加
すると見ていますが、

OpenAIがAIデータセンター向けに支払うお金は、2030年には、年間$620 billionにまで上昇
NVIDIAからの投資や、AMD株の売却益を含めても、キャッシュが$207 billion不足する
結果的に、OpenAIは、約束通りの規模でAIデータセンターを使うことができなくなる
と厳しい見方をしています。

これだけ楽観的な売り上げ予想を立てても、こんな試算になってしまうのは、OpenAIによる「AIインフラ投資計画」があまりにも巨額であるためです。

HSBCの予想通りになるとは限りませんが、そうなった場合のインパクトは巨額で、誰かが「ババを引く」ことになります。

Ilya Sutskever - We're moving from the age of scaling to the age of research

OpenAIの創業者の一人、Ilya Sutskeverの最新のインタビューです。彼の話し方は独特の曖昧さがあり、まるで「神のお告げ」を伝えるかのような雰囲気があります。

メッセージとしては、「大量のデータと計算資源さえ与えれば、いくらでもAIを賢くできるフェーズは終わり、今は再び、さらなる性能向上のための手法を見つけるべき『研究フェーズ』にある」と指摘しています。

つまり、OpenAIやAnthropicが主張する、「莫大な計算資源さえあればAGIを作ることができる」という主張は間違っている、もしくは、そうやって作ったAGIが社会にもたらす価値はそれほど大きくない、と指摘しているのです。

彼は、今のAIは、学習フェーズで全ての知識を詰め込もうとしている点が、「学び続ける能力」をもった人間の脳とは大きく異なり、AIを次のレベルに進化させるには、「失敗から学ぶ能力」が必要だと指摘しています。

何でも知っているけど進化が止まってしまった「学習済みのAI」よりも、15歳の子供のように、いろいろなものを学ぶ能力を持っているAIの方が、社会にもたらす価値が大きいと主張しているのです。

分かりやすい例として、今のAIがコーディングの際に、一つのバグを治すために別のバグを導入し、そのバグを治すように指示すると、最初のバグを再度導入してしまうような失敗を繰り返す点を挙げています。これは、Claude CodeやCodexを使っていてもしばしば起きることで、人間であれば、決して起こさないような間違いを平気で起こすことがあるので注意が必要です。

Ilya自身もAIベンチャーを立ち上げているので、若干のポジション・トークも含まれているとは思いますが、第一線の研究者から、「スケーリング則」に限界が来ていることを指摘している点は、とても価値が高いインタビューだと思います。

Google TPU v6e vs AMD MI300X vs NVIDIA H100/B200

GoogleのTPUとNVIDIAのGPUの比較が盛んにされている中で、「TPUの方が、GPUよりも電力あたりの能力が高く、トークンの生成コストが安い」という声が聞かれますが、少なくとも第６世代のTPUまでは、NVIDIAのGPUの方が効率も良く、安いことを数字で示してくれる、興味深いXへの投稿です。

しかし、Googleは、第７世代のTPUで大幅に性能を向上させて来たので、そちらの数字を見ない限りは何とも言えませんが、データが不足しており、まだ試算はできないそうです。

しかし、このデータを見ると「(TPUのような)ASICの方が圧倒的に高性能で安い」とは一概に言えないことが分かります。

京大おもろトーク番外編「おもちゃモデル」講演：時枝 正（スタンフォード大学 教授）2018年2月8日

Xでたまたま流れてきた画像ですが、あまりにも面白いので、最後まで見てしまいました。スタンフォード大学で教授をされている時枝正教授の実験を交えた講演ですが、「科学は本当に楽しいものだ」というものを再確認させてくれる、素晴らしい講演です。「物事を分かりやすく説明する手法」という観点からもとても参考になります。

このメルマガには、自分の子供に何を勉強させるべきか、どんな刺激を与えるべきかなどの質問がしばしば来ますが、結論から言えば、こんなビデオを心の底から楽しめる大人に育てることが何よりも大切だと私は思います（このビデオは子供には難し過ぎます。子供向けの映像としては、同じく時枝正教授による「学童保育所KuSuKu「ひものてじな」ダイジェスト版　スタンフォード大学　時枝 正 教授」という講演もあるので、そちらの方が適していると思います）。

物理はこの世界のすべての現象の元です。そこに興味を持つことが全ての始まりだと思います。私は、高校生の頃から「プログラミング」にハマって、それが仕事になりましたが、その根底には、科学、特に物理への興味と憧れがあります。

Elon Muskは、しばしば「first principles(第一原理)」という言葉を使いますが、これは、ニュートン力学のような自然現象を説明する基本原理に立ち返って、物事を見るべきだ、という考え方を指します。

AIがコードを書き、文章や映像を人間の代わりに生成してくれる時代になっても、最終的には、数学や物理の基本をしっかりと理解した人でなければ、AIを作ったり、AIを使いこなす側には立てません。AIやロボットの技術がどんなに進んでも、その基本になるのは、数学や科学であり、これまで以上に、理数教育が重要になると私は思います。

自動車業界が「ソフトウェア業界」に変わる？2040年には売上のほぼ4割へ

経産省がこのほど公開した資料によると、自動車販売におけるソフトウェアの売上金額は上昇を続けており、2040年に38％までに達するという試算があるそうです。

下記が記事中で紹介されている、自動車OEMの年別の売上予測とソフトウェア／ハードウェアの比率です。

2021年：418兆円｜ソフトウェア23兆円（6％）、ハードウェア395兆円（94％） 2025年：687兆円｜ソフトウェア76兆円（11％）、ハードウェア611兆円（89％） 2030年：912兆円｜ソフトウェア216兆円（24％）、ハードウェア696兆円（76％） 2040年：1,291兆円｜ソフトウェア494兆円（38％）、ハードウェア797兆円（62％）

Teslaは既に、FSDを一括で$8,000、サブスクリプションだと月額$99で提供しており（モデルの価格とは独立）、低価格モデルを出すと自動的に、ソフトウェアの比率が高まることになります。

しかし、重要なのは売上の比率ではなく、粗利率で、ハードウェアの粗利が15%程度で頭打ちになるのに対して、（ハードウェアのアップグレードを伴わない）ソフトウェアであれば、ほぼ100%の粗利が稼げる点が重要です。

そのためにTeslaは、

全ての車両にFSDに必要なハードウェア（FSDコンピュータ＋カメラ）を標準装備
それを可能にする、自社製チップの開発
ソフトウェアのOTA（Over The Air）アップデート機能の充実
End-to-Endのニューラルネットで構築されるFSD
人間のドライバーによる運転操作と映像の蓄積
を長年進めて来たのであり、これが旧来型の自動車メーカーにとっては、大きな参入障壁になります。

特にトヨタ自動車の場合、

長年、車載コンピュータやソフトウェアは外注に任せる体制で開発
社内にソフトウェア人材が育成できていない
経営陣がサラリーマンばかりで、ストックオプションの価値などが理解できていない
結果として、外部から優秀なソフトウェア・エンジニアを雇うことができない
トヨタ独自の品質管理体制が、ソフトウェアのアップデートを難しくしている
などの問題を抱えており、TeslaのようにFSDをソフトウェア・オプションとして提供するのは、非常に難しい（つまり、ハードウェア・オプションとして提供せざるを得なくなってしまう）と私は見ています。

GPU-HBMの境界が崩れる…次世代HBMにGPUコア内蔵

韓国語の記事ですが、AIチップの将来に関する、とても興味深いものなので紹介します。

日本語で要点を書くと、以下の通りになります。

現在主流の高帯域幅メモリ（HBM）とグラフィック処理装置（GPU）は別のチップだが、次世代HBMでは「HBMの下部基板（ベースダイ）」にGPUコアを直接組み込む構造が検討されている。
MetaやNVIDIAなどの大手テック企業が、この「メモリ＋演算コア一体型HBM」アーキテクチャの導入を模索しており、SKハイニックスやSamsung Electronicsなどと協業を検討中。
この方式の狙いは、データ転送距離の短縮と、GPU本体の負荷軽減 ― つまり、AIなど大容量データ処理における「速度＋電力効率」の大幅改善。
一方で、技術的な課題もある。ベースダイのスペースは非常に限られており、電力供給や熱の排出（発熱対策）が大きなハードル。これをクリアできるかが鍵。
この技術は、メモリとシステム半導体の境界が曖昧になり、半導体業界の競争構造にも大きな変化をもたらす可能性がある。国内企業にとってはチャンスである一方、対応が遅れればシステム半導体企業に“下請け”のような立場を強いられる懸念もある。
GPU向けのメモリ、HBM(High Bandwidth Memory)に関しては、韓国企業であるSKハイニックスとSamsung Electronicsが大きなシェアを握っています。現時点では、GPUを作っているNVIDIAやAMDに対してHBMを搭載したチップレットを提供し、それをGPUと繋ぎあわせた形のハイブリッドチップとして販売されています。

この話は、HBMチップの中にGPUコアを埋め込むことにより、高性能なAIチップをよりシンプルな構造で提供できる可能性を示唆しています。

このアプローチがどこまで現実的なのかは、この記事からだけでは判断できませんが、「NVIDIA１強の時代がどこまで続くのか」という観点から、頭の片隅に記憶しておいても良い話だと思います。

Marc Andreessen on the inversion of technology adoption of AI.

A16Z(シリコンバレーの大手VC)のMarc Andreessenによる、AIの導入が、コンピュータの導入の歴史と逆になっている点を指摘する興味深いコメントの紹介です。

コンピュータの場合、最初に導入したのは政府で、1940年代のことです。それが、大企業(50年代～60年代)、中小企業（70年代）と広がり、個人が導入するまで40年位以上がかかりました。

しかし、AIに関して言えば、個人がChatGPTを使い始め、それが中小企業に広まり、ようやく大企業や政府が重い腰を上げて導入を開始していると指摘しています。

Another super impressive use case... Nano banana is killing the game

Googleの最新の画像生成AI、nano banana proの使い方として、とても鋭いと感じたので紹介します。英語を勉強している中国人のために、ペットショップにある様々なものに、英語・発音記号・中国語のラベルをつけた画像を、簡単なプロンプトで生成させています。



重要な点は、この画像は「教科書」向けに生成しているのではなく、勉強している人が自分のためにその場で生成している点にあります。AIの進化により、コンテンツ生成のコストがゼロに近づくと、こんな使い方ができるようになるのです。

生成系AIの進化により、クリエーターの仕事がなくなる（もしくは単価が低くなる）ことを心配する声を良く聞きますが、それは通過点にしか過ぎず、その先には「オンデマンド・コンテンツ」「パーソナライズド・コンテンツ」「使い捨てコンテンツ」の時代が来るのです。

従来型の教科書は、その制作コストの高さゆえに、時間とコストをかけて作ったものを何万・何十万の人が利用していましたが、生成AIにより、一人一人の生徒の理解度や勉強スタイルに応じたテキストを、トピックごとにオンデマンドで作る時代に変わろうとしているのです。

そんな時代が来ようとしている時に、教科書向けのイラストや文章を書いていた人たちの仕事がなくなるかどうか、という話をしても意味がないのです。「作ったコンテンツのコピーを何万・何十万人に見てもらう・使ってもらう・読んでもらう」時代が終わろうとしているのですから。

ディスプレイ市場で中国に敗戦した「シャープ」「京セラ」「JDI」「ソニー」…撤退、退避、提携、独自路線とそれぞれ異なる生存戦略を展開する日本企業たちを分析

ディスプレイ市場に関しては、それほど頻繁に追いかけているわけではないので、認識をアップデートする意味で、とても良い記事でした。要点を簡単にまとめると、

日本のメーカーは、「前門の韓国（LG）、後門の中国（BOE）」という挟み撃ちにあっていて、シェアを落としている
スマホOLED市場は、すでに中国勢が席巻するレッドオーシャン
日本勢にとって「最後の牙城」とされてきたのが、プレミアム車載ディスプレイ市場は、OLED化の波に乗る韓国LGディスプレイの猛攻で崩壊
官民ファンドから4000億円以上の支援を受けながら債務超過状態に陥り、今はいちごアセットグループの支援を受け、経営再建を試みているJDI（ジャパンディスプレイ）は、次世代OLED技術「eLEAP（イーリープ）」で勝負をかけるが、自社工場を支える体力はないため、台湾InnoluxおよびCarUXに製造を委託する、「ファブライト・モデル」という戦略を選択
シャープは、赤字続きのディスプレイ事業を「レガシー事業」へと再定義し、「総合電機・ブランド企業」へと変貌
京セラは高信頼性BtoB市場へ「移行」し、過酷な環境下での「高信頼性」と「長期供給性」でニッチな市場を確保
ソニーは汎用パネルから事実上撤退し、AR/VRデバイス向けの「OLEDマイクロディスプレイ（Micro-OLED）」に特化
となります。

ちなみに、記事中に、JDIの台湾企業への製造委託に関して「この「日本（技術）＋台湾（生産）」という枠組みは、欧米の顧客が求める『脱中国（チャイナフリー）サプライチェーン』のニーズに応える合理的な戦略」との記述がありますが、違和感を感じました。米国政府は、半導体の製造を大きく台湾に依存している現状に強い危機感を感じ、半導体工場の米国への誘致などに巨額の税金を費やしており、その流れに逆行するようにすら感じました。

Businesses Still Dream of Using AI to Replace Enterprise Apps

企業向けアプリがAIに置き換えられるという話は以前からありますが、実際にはSalesforceやWorkdayのような大規模システムをAIが完全に代替するには、まだ信頼性もガバナンスも不足しています。ただし「部分的にAIが業務を奪い始めている」という点では、すでに静かな変化が進行中です。

Databricksの顧客の中には、自社のデータレイクを使ってITヘルプデスクの一次対応やソフトウェア保守、採用などの定型業務をAIエージェント化する動きが広がっています。Lakeside Softwareでは、Workdayの操作をAIに学習させ、HRシステムを丸ごと独自AIに置き換えた企業まで出てきました。もちろんこれは例外的ですが、「AIがGUIを観察し、操作し、人間の代わりにアプリを使う」という未来が、一部では現実になってきています。

一方で、既存プレイヤーは冷静です。ServiceNowもWorkdayも「AIを載せただけでは大規模な業務プロセスは再現できない」「セキュリティ、データ管理、ワークフローが本体だ」と指摘しており、これは事実です。アプリの表面のUI操作を模倣しても、その裏側にある膨大な仕組みまで“再構築”できるわけではありません。

それでも、AIが人間による定型作業を侵食しつつあるのは間違いありません。興味深いのは公共セクターで、メリーランド州ではAnthropicとPerceptaのエンジニアが現場に入り込み、不動産情報の公開フローや福祉制度案内をAIチャットボット化し、数週間かかっていた業務が1日以内に短縮されました。6月以降、60万人以上が利用したと言います。

AIはエンタープライズアプリを一気に破壊するわけではなく、まずは“アプリを使う人間の行動”を代替する形で、周縁部から静かに溶かしていく。大規模アプリの内部構造を変えるのではなく、その周りにあった無数の人的作業を次々とAIが吸収していく。今回の事例は、そんな変化がすでに始まっていることを示しているように感じます。

AI-assisted science could compress 100 years of progress into just 10 to 15 years

Googleのチーフ・サイエンティスト、Jeff Deanのインタビューの一部を切り取った映像ですが、AIが社会にもたらす最も大きなインパクトとして、「科学技術の発展」の加速に期待していると語っています。過去100年間に起こった（医療、自動車、飛行機、コンピュータ、インターネットなど）科学技術の発展は、私たちのライフスタイルを根本的に変えましたが、同様の発展が、今後10～15年間の間に起こる可能性を指摘しています。

Berkshire Hathaway Takes $4.3 Billion Stake in Alphabet

Warren Buffettが率いるBerkshire Hathawayが、Googleの親会社Alphabetの株を$4.3 billion分購入したことが明らかになったことを報じる記事です。

Warren Buffettは、「自分に理解できない会社の株は購入しない」というポリシーで、当初はハイテク株には手を出していませんでしたが、今では、Apple、Amazon、Alphabetの株式を所有しています。

Warren Buffettは、ファンダメンタル（売り上げ、利益、利益率、成長率）などがしっかりし、かつ、株が割安な会社の株しか購入しないことが知られており、Alphabetのポートフォリオへの組み込みには、Alphabetのファンダメンタルがしっかりとしていることを示しています。

質問コーナー

【質問】

AI時代にあるべき組織の形態について質問です。

中島さんが以前からご指摘されている通り、AIネイティブな新興企業が少人数で大企業並みの売り上げを出す兆しが出てきています。このような中で、AI以前からある既存の大企業は生存のために、今後どのように組織形態やビジネスの仕方を変えて行く必要があるとお考えでしょうか。規模が大きな企業ほど大きな課題になるのではと想像いたします。

《回答》

人材の流動性が高く、かつ、競争原理・経済原理が働きやすい米国においては、

自らリストラを断行して生き延びる企業
必要なリストラができずに衰退して行く企業
プライベート・エクイティなどに買収され、強制的にリストラされる企業
AIを最大限に活用して、破壊的な革命を業界にもたらす企業
が入り混じる形で、社会に大きな変化が生じると私は見ています。

日本の場合、大企業が人を解雇することは非常に難しいしため、米国と比べるとゆっくりとした形でしか変化が起こらないと思いますが、AIによる進化圧は国境をまたいでかかり続けるので、そこから免れることは難しいと思います。

日本社会がリストラをどのくらい許容するのか、競争原理や経済原理がどのくらい働くのか、日本政府がどう動くのか、などの要因によって、その結果もプロセスも大きく違うものになるので、一言で「どうなります」とは、誰にも言えないと思います。

いずれにせよ、単純作業や定型業務を可能な限りAIに任せることにより、一人当たりの生産性を上げることは、会社の大きさに関わらず必要なことであり、そんな仕事のやり方を自ら手を動かして学ぶ、痛みを恐れずに前に進むことが何よりも大切だと思います。

【質問】

ゲームエンジンのUnityがEpic Gamesと協業を発表しました。Unityの株価を見ると今年の4月から2倍以上になっているので、Unityが注目されていると感じます。

中島さんのUnityに関する見解をお聞きしたいです。

《回答》

この件（Unity and Epic Games Together Advance the Open, Interoperable Future for Video Gaming）ですね。

ゲーム業界全体にとって、とても大きな話です。これまでは、UnityとEpic Gameがライバルとして戦う構図だったものが、Fortniteの成功（＝プラットフォーム化）と、Unityの戦略ミス（開発者向けのビジネスモデルの変更）の結果、Unityが、Unreal Engine + Fortnite というプラットフォームの上で、ゲームの開発環境を提供する会社になるというレイヤーの変化が起こったと解釈して良いと思います。

どう実装するのかは、この発表だけでは明らかではありませんが、Unity（Unity社が提供する開発環境）で作ったゲームが、Fortnite上で動くようになるというのは、とても画期的な話です。これにより、Epicは、Unityが抱えるゲーム開発者をForniteエコシステムの中に取り込むことができるし、Unityは、彼らが提供する開発環境を開発者に使い続けてもらうことができます。

さらに、Unityが提供するアプリ内課金のシステムをUnreal Engine上でゲームを開発している開発者が使えるようになるなど、かなり面白い動きであり、業界全体にとっても良い話だと思います。

今回の提携は、Unityにとっても悪くない話ですが、Fortniteというプラットフォームを持つEpicの強さがさらに強調される話でもあります。今後、Fortniteがプラットフォームとして、さまざまなゲーム機やパソコンに普及し、そこで人々がゲームを購入したり、ゲーム内課金をしたりという、大きなエコシステムが作られる可能性は大きいと思います。

極端な話、Appleのアプリストアでゲームを購入する時代が終わってしまっても不思議はないぐらいの大きな話です。Epicは、独自のアプリストアを持つことに対して、Appleと長年戦って来ましたが、Epicが最終的に目指している世界は、ここにあったのだと今になると分かります。

【質問】

最近、通信速度が早く消費電力を抑えられ光ネットワーク技術が発展し、従来の銅線からデータセンター置き換わりつつあるという記事を読みました。これは今後どんどん進んでいく流れなのでしょうか？

また、中島さんのような業界人の方にとってはいつぐらいから織り込まれていることなのでしょうか？Googleトレンドで検索数を見ると今年の8月頃から急に増えており、その頃から$LITE等の関連銘柄も一掃急騰し始めたように見えます。

《回答》

光ネットワークはスピード面でも電力の消費面でも有利なので、基本的にはそちらにシフトすると考えて間違いなく、投資家たちもすでに注目していると思います。ただし、そのシフトがどのタイミングで起こり、そこでどの会社が大きく利益を上げるかに関しては、さまざまな意見があり、結果として一部の銘柄が急騰していると考えて良いと思います。

この分野の株に投資する際に、一つ意識しておくべき点は、NVIDIAが単にGPUを売るビジネスから、AIスーパーコンピュータを売るビジネスへとシフトしている点です。当然ですが、ネットワークも「AIスーパーコンピュータ」の一部であり、ネットワークだけで勝負する会社が取るべき戦略については良く考えておく必要があります。

NVIDIAが（光ネットワークの技術を持つ）ベンチャー企業を一社買収しただけで一気に勝負がついてしまう、などの激変が起こっても不思議はない業界です。

【質問】

近年ドローンの社会実装を加速させるため、米国FAAや欧州EASAが空域管理システムUTMを活用し、目視外飛行（BVLOS）の標準化と拡大を目指しています。

現在はNASA、Alphabet傘下のWingなど国の機関や民間企業が上記のようなシステムを開発しており、実装されることで安全にドローン配送、検査、監視などが行われると期待されています。軍事的な需要も考えられ、また将来的にはエアモビリティにも応用を期待されていると言われています。

規制の整備など、社会実装に時間がかかっているものの、今後ドローンのソフトウェア分野、ひいては空域市場の拡大について、短期～中長期目線ではどうお考えでしょうか。

《回答》

私は、この分野に関しては、とても強気です。AIがロボット・ビジネスに大きな変化をもたらしつつありますが、同じことがドローン・ビジネスに対しても必ず起こります。特にドローンの場合は、個々のドローンがエッジAIを持ちながら、複数のドローンを群としてコントロールするAIという組み合わせにより、これまで人が操縦するドローンではできなかったことができるようになります。

結果として、ドローンを適用できる分野が大きく広がる可能性があると私は見ています。技術さえ進化すれば、ミツバチの代わりに受粉を助ける超小型ドローン、小型レーザーで害虫を駆逐するドローン、工事現場で自動運転重機器の目となって飛び回るドローンなどが現実的なものになります。

【質問】

昨年社内にMicrosoft Copilotが全社導入され、生産性向上のためにCopilotを使い倒すように全社から指示が出ています。翻訳や議事メモ作成など簡単な仕事はCopilotで代替できるのですが、業務フローそのものを変えようとなるとPower系アプリを使って社内他基幹システムやSaaS製品との連携が必要だったりするなど、ハードル高く、自分の代わりにAIが仕事をしてくれる世界はまだ遠い気がします。Copilotはまだまだおもちゃに近い感覚を覚えます。

今後Copilotはどこまで進化していくのでしょうか。Microsoft はCopilotを使ってどんな世界を実現したいのでしょうか。

《回答》

Copilotは、今やMicrosoftが提供する「AI機能」のブランド名なので、さまざまな形のCopilotがMicrosoftから提供されると見て間違いないと思います。

Microsoftが目指すところは、「Microsoftが提供するソフトウェア＋サービスがあらゆるビジネスにとってなくてはならないツール」になることなので、ある意味、なんでもやってくると思います。

今の段階で、他のシステムとの連携が不得意であるなら、それを解決するための何らかの仕組みを入れるのがMicrosoftの役割だとも言えます。

他のところでも「単純作業や定型業務はAIにやらせることにより従業員一人当たりの生産性を出来るだけ向上させる」ことが重要と書きましたが、「MicrosoftのCopilotがあるからこそ、それが可能になった」と顧客に言ってもらえる環境を作ることが、これからのMicrosoftのミッションだとも言えます。

【質問】

現在、40歳手前で責任のある仕事も増えてきたため、翌朝のパフォーマンスに影響しないように、お酒を控えたいと思っています（トランプ大統領は酒を一滴も飲まないというし、イーロン・マスクもほとんど飲まないと聞きます。日本人経営者ではニデックの永守さんも断酒しています）。

一方で、酒はそれなりに飲めるため、急に酒を控えると場の空気が冷めないかと危惧しています。中島さんは会食の際はお酒はどのくらい飲まれますか？　また、中島さんは仕事のパフォーマンスのために断酒するという判断をどう思われますか？

《回答》

私は一滴も飲みません。下戸なので、学生時代は先輩に「飲め」と絡まれて苦労しましたが、社会人になってからはキッパリと断っています。米国ではもちろんのこと、日本で仕事をする際にも、最初から「この人はお酒を飲まない人だ」と理解してもらえれば問題ありません。

ちなみに、米国では人前で泥酔することは御法度（＝社会人として失格）で、二日酔いでパフォーマンスが落ちるような人はすぐに解雇されてしまいます。

【質問】

broadcomについて２つ質問があります。

Broadcom の ASIC（カスタムAIチップ）は、エンジニアの視点から見て、将来的に NVIDIA の GPU を性能や市場支配力の点で超えることは現実的でしょうか？

VMWareの買収はAIにオールインしすぎることのヘッジとして見ることはできませんか？AI インフラ投資が急増する一方で、VMWare のような企業向け基盤ビジネスは安定した収益源にも思えます。

《回答》

技術的に言えば、特定の用途に最適化することにより、電力あたりの性能を（汎用コンピュータである）GPUより高くすることは可能です。また、NVIDIAの粗利の分だけコストを抑えることも可能です。だからといって、NVIDIAのGPUを凌駕できる保証がないところが、この業界の面白いところです。最新のAIの研究をするには、NVIDIAのCUDAを使うことが必須であり、その強さは圧倒的です。

BroadcomによるVMWareの買収は、ヘッジというよりは、安定したキャッシュフローを得るための財務戦略だと私は理解しています。ASICの開発には大きな初期投資が必要ですが、Googleなどの顧客からASICの開発を委託された際に、必要な開発費をもらって受注型のビジネスをするか、共同開発をして（自ら開発のリスクを負って）ライセンス・ビジネスにするかを考えた際に、成功報酬がもらえる後者の方が良いと経営陣が考えた結果の買収だと私は解釈しています。

【質問】

Claude Opus 4.5 が登場しましたが、実際に触ってみると非常に高性能な反面、トークン単価が高く、私のようにプロプランで Claude Code Sonnet を使いながらバイブコーディングを行うスタイルだと、すぐ使用上限に達してしまいます。

中島さんご自身は、日常的なコーディングやプロトタイピングでは、どのモデルをメインに利用されていますか？

《回答》

私はデフォルトのSonnet 4.5を使っていますが、特に不自由を感じたことはありません。たまにそれでうまく行かないときは、モデルを切り替えるのではなく、OpenAIのCodexを試したりしています。

【質問】

都心部でデータセンターやオフィスビルの不動産開発をしています。

超高層ビル等の大規模案件で長期プロジェクトが多く、いま設計をしても完成が10年後になるケースも多々ある中、今後の不動産価値についてのビジョンを日々模索しています。

そこで、10年後に完成する東京都心の大規模なオフィスビルの在り方は、どのようなものがフィットするか中島さんのご意見を伺えると有難く存じます。

一例として

ロボットが多数入り込んでくるため、今以上の電源容量が求められる
一か所に集まって働く必要がないので大規模なオフィス不動産は不要
地方郊外のAIサーバーを遠隔監視する機能に特化する
どのような用途にも変更できるよう十分な可変性を持たせておくなどがすぐに思いつくところですが、他の観点があればご教示いただけると幸いです。

《回答》

不動産開発は私の専門ではないので、思いついたことを五月雨式に書きます。

少し前に、私がシアトルのディベロッパーに同様の質問をしたところ、「自動運転の時代になると駐車場が不要になる可能性があるため、駐車場は地下につくらず、地上に配置することにより、後からオフィススペースに変更できるような設計にしている」という返事が返って来ました。

AIがますます重要になり、社内にAIサーバーを持つことが必要になることを想定し、都市ガスを利用した発電システムを設置する、蓄電池を設置する、オフィスの外壁には太陽光パネルを張り巡らせる、などして電力を十分に確保しておくことは大切だと思います。

オフィスビルの一部に最初からAIデータセンターを設置しておき、店子に対しオンプレサーバーとして提供できる環境にしておく（余ったものは外部にレンタルする）、冬場はサーバーから出た熱を暖房に使う、夏はトイレのタンク経由で熱をビルの外に出す、などできることはたくさんあると思います。

【質問】

OpenAIのProモデルについてお伺いしたいです。

現在Thinkingモデルを利用していますが、Proモデルとの機能・性能面での違い、および月額100ドルの料金に見合う価値があるかどうか、ご意見をいただけますでしょうか。

Codexを使用しているのですがレート制限に達することが時々あり、もしProモデルに価値があれば、proプランへのアップグレードも視野に入れたいな思っています。

《回答》

私自身は、OpenAI、Anthropic、Googleのサービスを使い分けていることもあり、OpenAIに関しては、月額20ドルのPlusプランで十分だと考えています。OpenAI一本で行くのであれば、Proプランも悪くないと思います。

【質問】

「世紀の空売り」で知られる投資家マイケル・バーリ氏がNvidia, Palantirの下落を見込んでプットオプションを取得しています。この動きはAI・半導体関連の過熱感に警戒していると思います。

私はこの先AIが経済を引っ張っていくと思いますが、AI関連の銘柄に集中しすぎではないかと感じます。中島さんは現在のAIのトレンドに関して、どのように考えておられますか？

《回答》

過熱感があるのは事実で、マイケル・バーリ氏のように逆張りをする人がいるから、市場に下向きの圧力がかかり、市場が健全なレベルに保たれるという面もあるので、必ずしもネガティブに捉える必要もないと思います。

今のレベルが高すぎるのか、まだまだ上がるのかは私には分かりませんが、AIは日々進化を続けており、AIが産業革命と呼べるほどの大きなインパクトを社会に与えることに関しては、疑いの余地がないと私は考えています。

【質問】

先週の質問コーナーで触れられていた「こまめにcommitするコーディングスタイル」について、特にコミットメッセージの運用ルールが気になりました。

普段、・どの粒度でcommitしているか・コミットメッセージの書き方やフォーマット・自動生成ツールを使用するかどうか

といった点を、どのようにルール化されているのか教えていただけると嬉しいです。

《回答》

Commitの粒度は、他のエンジニアと比べて小さい方だと思います。一つのプロジェクトに集中しているときには、1日に数回から数十回のCommitをしています。特にCommitのタイミングは決めていませんが、私は一つのタスクをさらに小さなタスクに分けて実行するため、そのタスクごとにCommitするイメージです。

Commitの粒度を小さくしている理由の一つは、一つのタスクに対するサンクコスト（かけてしまった手間）を極力小さくすることにより、「書いたコードをあっさりと捨てる」ことを容易にすることにあります。コードに何か変更をした時に、思うように動かなかったり、副作用が出たりして、デバッグをしてもそのバグが解消できなくなる時がしばしばあります。

そんな時には、私は一度書いたコードを全て捨てて（一つ前のCommitまで戻り）、新たな気持ちでコードを書くようにしています。Commitの粒度が大きくなると、「書いたコードを捨てる」ことがもったいなくなってしまうので、それが嫌なのです。

こんな働き方をする際には、ユニット・テストはとても重要です。コミットごとにユニット・テストをする行為は、足場を一歩一歩固めながら山を登っていくイメージに似ています。一気に登ろうとせず、「一歩、一歩、着実に」登るイメージです。

ちなみに、コミットの粒度は小さいですが、mainブランチへのマージは、複数のコミットをひとまとめにして、プルリクエストの形にしてからマージします。上に「一つのタスクを小さなタスクに分けて」と書きましたが、分ける前のタスクがプルリクエストの粒度です。

なので、コミットごとのコメントは、自分にだけ分かれば良いので、あまり丁寧には書きません。プルリクエストを作る段階で、どんな機能を追加したのかをしっかりと書く方が重要です。

なので、私が関わっているプロジェクト、例えばMulmoCastは、Commitだけを見ても何が起こっているかは分からないと思います。Mergeされた一連のプルリクエストを見ると、何が起こっているかが分かります。

【質問】

MulmoChatの思想には共感するところが多いです。多くの機器は、たくさんの種類を持っているにも関わらず、人間が使い方を分からないことで困り事を解決できないケースが多々あると思います。そういうケースをLLMを仲介役にすることでも解消できるし、そのニーズも結構あるのではないかと考えています。

《回答》

フィードバック、ありがとうございます。とても良い励みになります。さまざまな機器の使い方の説明などにも、MulmoCastを活用してほしいと考えていました。機器のメーカーが活用するのはもちろん、ユーザーが必要に応じてLLMに依頼して使い方の説明ビデオを作ってもらうなどの使い方も是非ともして欲しいと考えています。

【質問】

中島さんの「The Dawn of the AI-Native Operating System」を拝読して気になったのですが、この世界が実現すると、WindowsやLinuxなどのUIを司っているOSの価値が（すくなくともUI領域では）無くなるので、「OSの寡占化の時代に終止符が打たれる」と感じました。

OSの存在など気にせずコンピューティング（？）パワーを使うことができる、という世界ですね。

その際に、業務領域でのPCの使われ方の、一番レガシーな部分、つまり（名前は書きませんが）表計算ソフトはどうなるのだろうか？という疑問が残ります。

現時点では、どのような高機能な業務システムを導入しても、結局表計算ソフトの活動領域だけは残ってしまい、それが複雑化して属人化の温床となります。言い換えると、これが日本企業におけるデジタル化の妨げになっているのではないかと暴言できますが、中島さんのご節の世界で表計算ソフトはどのような未来を迎えるとお考えでしょうか？

《回答》

私自身にも、それが既存のソフト（およびそのビジネス）にどんな影響を与えるかは見えていませんが、一つだけ明らかなことは、「人が手作業でスプレッドシートを作る時代」が終わるということです。

もちろん、LLMに対して指示を出すのは人間だし、作ったものを活用するのも人間ですが、人間がちまちまと手作業でスプレッドシートを作り、それが俗人化してメンテナンスできなくなるような時代は終わらせるべきです。

この話は、「使い捨てソフト」とも密接に関連する話であり、「アプリケーションとは何か」「プログラミングとは何か」というソフトウェアの根底に関わる話なので、とことん突き詰めてみたいと考えています。

【質問】

質問ではないのですが、今週のメルマガで、

私の息子は高校生で動物が大好き（特に犬が大好き）です。将来は動物に関わる仕事をしたいと言っています ... AI時代においても残る、人と動物の関わり方について中島さんの考えをお聞きしたいです

という質問があったので、ちょっとご紹介ですが、今、自分が働いている Earth Species Project (ESP) https://www.earthspecies.org/ という非営利団体では、AI を使って動物のコミュニケーションを解読することをミッションにして活動しています。

例えば、クジラの出す音と行動の関係や、鳥の鳴き声のパターンなどを、データから自動で解析するといった研究をしています。

最近では、動物のコミュニケーションに関して質問に答えられる基盤モデルである NatureLM-audio をリリースしました：

https://www.earthspecies.org/blog/introducing-naturelm-audio-an-audio-language-foundation-model-for-bioacoustics

AI × 動物の分野も進歩が早く、我々の組織ではこの分野を ALP (Animal Language Processing) と呼んで新しい分野として提案しています。ご参考まで。

《回答》

ありがとうございます。私はハワイの海で鯨の声を聞きならがSUPをするのが趣味なので、是非とも彼らが何を語っているのか理解したいと思います。

【質問】

ロボット領域における日本の勝ち筋についてご質問です。

先日、中国の深センにて実施の中国最大規模のテック系展示会である中国ハイテクフェア（CHTF）を視察し、ロボット・ドローン・EVなどAI実装領域における中国の底力を強く感じました。

特に印象的だったのは、UnitreeやUbtechのような日本でもよく聞く完成品メーカーだけでなく、それらに部品を供給するメーカー（ロボットの「手」メーカー、「膝/腰関節」モーターメーカー、「指関節」モーターメーカー、「指先」センサーメーカーなど）が幅広く存在し、部品レベルまでの産業エコシステムが完成している点であり、もはや“組み立てる国”ではなく、“実装を支える国”に進化していると感じました。（100m*100mくらいのAI/ロボット展示ホールの半分近くがロボット部品メーカーを占めている状況）

米国がAIモデル（頭脳）で覇権を握るのに対し、中国はAIを動かす身体＝物理レイヤーで主導権を狙っているように見えます。

こうした構図の中で、 ロボット領域において日本が取りうる現実的な勝ち筋をどのようにお考えでしょうか。「脳」と「身体」をつなぐアプリケーションのレイヤーについてはまだ覇権をとっている企業や国はないとおもうので、個人的には、この領域で日本独自のアニメ・漫画などのIPコンテンツや、医療介護サポート領域などでうまく振る舞え場可能性もあるのではと感じるのですが、是非ご見解を伺えれば幸いです。

《回答》

私はハードのビジネスをあきらめるべきではないと考えています。日本には、これまで自動車産業を支えてきた数多くの中小企業があるし、高専という人を育てる良い教育システムも存在します。コストだけの戦いでは厳しいと思いますが、米国がサプライチェーンの中国依存を減らそうとしている今、日本がそこを担う、とても良いチャンスだと私は見ています。

特に日本企業に頑張って欲しいのは、部品工場も含めた工場の自動化です。大量に人を使う限りは、コストで中国と戦うのは困難です。しかし、無人工場であれば技術力勝負に持ち込めるし、今後は、工場の無人化技術そのものも大きなビジネスに発展すると私は見ています。

【質問】

先日アメリカへ行く機会があったのですが、リビアンの車を見かけました。

私も株を保有してからは初めて見かけたのですが、中島様はテスラからリビアンに乗り換えることはしないでしょうか？

《回答》

私もリビアンを良く見かけるし、知り合いにも乗っている人がいますが、私自身は、しばらくはTesla一途で行く予定です。FSDがどこまで進化するのか見ていたいし、その後のOptimusにも大いに期待しています。

【質問】

私は美容室を運営しております。

2025年11月25日号の質問コーナーで、散髪の自動化にはチェーンやフランチャイズ・ビジネスも相性が良く、大きなビジネスになる予感があるとの内容を拝見し、挑戦したい気持ちを刺激されました。

取り組むにあたりいきなり全自動化は様々な面でハードルが高く感じているため、まずは散髪の効率化、半自動化を目指したいと考えております。

男性の髪型に関しては、既存のバリカンに新たな機能を追加し、アップデートする事で、現状の散髪の生産性やクオリティを上げられるのではと考えております。

ただ、社内にはハードウェアを開発する知見やリソースがありません。

こういった既存にないハードウェアを作る場合、どのように進めていくのが良いのか、また、どのような企業に依頼するのが適切なのか、アドバイスをいただけますと幸いです。

《回答》

とても良い発想だと思います。ハサミとクシを使いこなせるロボットの誕生までにはまだ時間がかかりますが、バリカンには長い髪が切れないという欠点があります。長い髪を切ることが可能なバリカン（ひょっとしたらバリカンとは大きく異なる形状・仕組みのものかも知れませんが）をまず作り、それをプログラマブルにすることにより、一歩づつ自動化に近づけて行くという戦略です。

まずはプロトトタイプ作りから始めるのが良いと思いますが、それに相応しい企業の名前がすぐには思いつきません。私であれば、

近くの高専に相談に行く
大学の機械工学の先生に相談する
DMM.make AKIBAを訪問して、そこに出入りしている人たちに相談してみる
などからスタートするだろうと思います。
